{"meta":{"title":"Hexo","subtitle":"","description":"","author":"John Doe","url":"http://example.com","root":"/"},"pages":[],"posts":[{"title":"opencv","slug":"opencv","date":"2022-01-10T12:50:21.000Z","updated":"2022-01-10T12:51:14.519Z","comments":true,"path":"2022/01/10/opencv/","link":"","permalink":"http://example.com/2022/01/10/opencv/","excerpt":"","text":"题目要求：了解opencv的DNN库，给定一张自然场景图片，使用训练好的yolov3模型，进行目标检测结果输出。 分析：1）opencv的DNN模块集成了很多深度学习模型，包括人脸检测、图像分类、分割、目标检测等，集成了Pytorch、tensorflow、paddlepaddle等模型框架（参看代码库OpenCV/dnn）2）深度学习推理模型一般步骤：加载模型，包括配置文件和权重文件；输入图像预处理，转换成模型可接受的文件类型和尺寸；模型预测后处理，对于目标检测，主要是NMS后处理方法； 结果展示： 12345678910111213./bin/yolov3Predict -h#######Usage: yolov3Predict [params] image confThreshold nmsThresshold -?, -h, --help, --usage (value:true) opecv based deep learining demo image Image to process confThreshold (value:0.5) confidence threshold, default 0.5 nmsThresshold (value:0.3) nms threshold, default 0.3 1./bin/yolov3Predict data/test.jpg 代码示例： yolov3Predict.cpp 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110//yolov3Predict.cpp/*@File :yolov3Predict.cpp@Description: :@Date :2022/1/9 20:02:10@Author :@version :1.0*/#include&lt;iostream&gt;#include&lt;string&gt;#include&lt;sstream&gt;#include&lt;fstream&gt;#include&lt;vector&gt;using namespace std;#include&lt;opencv2/highgui.hpp&gt;#include&lt;opencv2/core.hpp&gt;#include&lt;opencv2/imgproc.hpp&gt;#include&lt;opencv2/dnn.hpp&gt;using namespace cv;using namespace dnn;#include&quot;utils.hpp&quot;// define command parsebool parseParam(int argc, char** argv, const char* keys, Mat&amp; img, float&amp; confThreshold, float&amp; nmsThresshold)&#123; /* @description : command parse function @param : int argc : main argc char** argv: main argv keys : command parse keys img : the image to read confThreshold : confidence threshold setting nmsThresshold : nms threshold setting @Returns : (ref returns) */ CommandLineParser parser(argc, argv, keys); if(parser.has(&quot;help&quot;))&#123; parser.printMessage(); return false; &#125; // check commoand format if(!parser.check())&#123; parser.printErrors(); return false; &#125; // get image String imgFile = parser.get&lt;String&gt;(0); img = imread(imgFile); if(img.empty())&#123; cout &lt;&lt; &quot;error to load test image. &quot; &lt;&lt; endl; return false; &#125; // get confidence threshold confThreshold = parser.get&lt;float&gt;(1); // get nms threshold nmsThresshold = parser.get&lt;float&gt;(2); return true;&#125;int main(int argc, char** argv)&#123; const char* keys = &#123; &quot;&#123;help h usage ? | | opecv based deep learining demo&#125;&quot; &quot;&#123;@image | | Image to process&#125;&quot; &quot;&#123;@confThreshold | 0.5 | confidence threshold, default 0.5&#125;&quot; &quot;&#123;@nmsThresshold | 0.3 | nms threshold, default 0.3&#125;&quot;&#125;; Mat img, blob; float confThreshold, nmsThresshold; // update data if(!parseParam(argc, argv, keys, img, confThreshold, nmsThresshold))&#123; return 0; &#125; // load model string classFile = &quot;model/coco.names&quot;; ifstream fin(classFile.c_str()); string line; vector&lt;string&gt; classes; while(getline(fin, line))&#123; classes.push_back(line); &#125; string modelCfg = &quot;model/yolov3.cfg&quot;; string modelWeg = &quot;model/yolov3.weights&quot;; Net yolov3 = readNetFromDarknet(modelCfg, modelWeg); yolov3.setPreferableBackend(DNN_BACKEND_OPENCV); yolov3.setPreferableTarget(DNN_TARGET_CPU); // convert image to blob format blobFromImage(img, blob, 1/255.0, Size(416, 416), Scalar(0,0,0), true, false); yolov3.setInput(blob); vector&lt;Mat&gt; outputs; // model predict yolov3.forward(outputs, getoutputsName(yolov3)); // post process (nms) postProcess(img, outputs, classes, confThreshold, nmsThresshold); // time cost vector&lt;double&gt; layersTime; double freq = getTickFrequency() / 1000; double t = yolov3.getPerfProfile(layersTime) / freq; string label = format(&quot;time consuming: %.2f&quot;, t); cout &lt;&lt; label &lt;&lt; endl; imshow(&quot;input&quot;, img); imwrite(&quot;output.jpg&quot;, img); waitKey(0); return 0;&#125; utils.cpp 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143/*@File :utils.cpp@Description: :@Date :2022/1/9 20:11:10@Author :@version :1.0*/#include&lt;string&gt;#include&lt;cmath&gt;#include&lt;memory&gt;#include&lt;iostream&gt;using namespace std;#include&lt;opencv2/core/utility.hpp&gt;#include&lt;opencv2/highgui.hpp&gt;#include&lt;opencv2/imgproc.hpp&gt;#include&lt;opencv2/core.hpp&gt;#include&lt;opencv2/dnn.hpp&gt;using namespace cv;using namespace dnn;#include&quot;utils.hpp&quot;Scalar randColor(RNG&amp; rng)&#123; /* @description : generate randow color @param : rng : random number generator object @Returns : Sacalar() : BGR scalar */ auto iColor = (unsigned)rng; return Scalar(iColor&amp;255, (iColor &gt;&gt; 8)&amp;255, (iColor &gt;&gt; 16)&amp;255);&#125;// get model output namevector&lt;string&gt; getoutputsName(Net&amp; net)&#123; /* @description : get model outputs name @param : Net : deep learning model @Returns : names : model output names */ static vector&lt;string&gt; names; if(names.empty())&#123; // get output layer idx vector&lt;int&gt; outLayers = net.getUnconnectedOutLayers(); // get all namenames vector&lt;string&gt; layersName = net.getLayerNames(); names.resize(outLayers.size()); for(size_t i = 0; i &lt; outLayers.size(); i++)&#123; names[i] = layersName[outLayers[i] - 1]; &#125; &#125; return names;&#125;// draw prdict result on imagevoid drawPred(vector&lt;string&gt; classes, int classId, float conf, int left, int top, int right, int bottom, Mat&amp; frame)&#123; /* @description : drop boxes and confidence on frame @param : classes : the total classes list classId : the predicted class id conf : predicted confidence left : left location top : top locatioin right : right location bottom : bottom location frame : the image to draw @Returns : (ref return) */ // draw rectanle for object detected rectangle(frame, Point(left, top), Point(right, bottom), Scalar(255, 255, 255), 1); // set rectangle for label show string conf_label = format(&quot;%.2f&quot;, conf); string label = &quot;&quot;; if(!classes.empty())&#123; label = classes[classId] + &quot; : &quot; + conf_label; &#125; int baseLine; Size labelSize = getTextSize(label, FONT_HERSHEY_SIMPLEX, 0.5, 1, &amp;baseLine); top = max(top, labelSize.height); rectangle(frame, Point(left, top - labelSize.height), Point(left + labelSize.width, top+baseLine), Scalar(255, 255, 255), FILLED); // put label text on image putText(frame, label, Point(left, top), FONT_HERSHEY_SIMPLEX, 0.5, Scalar(0, 0, 0), 1, LINE_AA);&#125;// post process (NMS) for object detectionvoid postProcess(Mat&amp; frame, vector&lt;Mat&gt;&amp; outs, vector&lt;string&gt; classes, float confThreshold, float nmsThresshold)&#123; /* @description : post process predict result to get suitable box to display @param : frame : image to process and return outs : predicts result classes : the total classes list confThreshold : confidence threshold setting nmsThresshold : nms threshold setting @Returns : (ref return) */ // get classId, confidence and boxes vector&lt;int&gt; classIds; vector&lt;float&gt; confs; vector&lt;Rect&gt; boxes; for(size_t i = 0; i &lt; outs.size(); i++)&#123; float* data = (float*) outs[i].data; for(int j = 0; j &lt; outs[i].rows; j++, data += outs[i].cols)&#123; // get socres for detectd class and scores Mat scores = outs[i].row(j).colRange(5, outs[i].cols); Point classIdPoint; double conf; // get min max value in socores with idx minMaxLoc(scores, 0, &amp;conf, 0, &amp;classIdPoint); // filter too small confidence if(conf &gt; confThreshold)&#123; int x = (int) (data[0]*frame.cols); int y = (int) (data[1]*frame.rows); int w = (int) (data[2]*frame.cols); int h = (int) (data[3]*frame.rows); int left = x - w / 2; int top = y - h / 2; classIds.push_back(classIdPoint.x); confs.push_back((float)conf); boxes.push_back(Rect(left, top, w, h)); &#125; &#125; &#125; // NMS operation vector&lt;int&gt; idxs; NMSBoxes(boxes, confs, confThreshold, nmsThresshold, idxs); for(size_t i = 0; i &lt; idxs.size(); i++)&#123; int idx = idxs[i]; Rect box = boxes[idx]; drawPred(classes, classIds[idx], confs[idx], box.x, box.y, box.x+box.width, box.y+box.height, frame); &#125;&#125;","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2022-01-09T23:48:43.563Z","updated":"2022-01-10T12:48:33.524Z","comments":true,"path":"2022/01/10/hello-world/","link":"","permalink":"http://example.com/2022/01/10/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment command1234$ hexo clean$ hexo g$ hexo d$ hexo server","categories":[],"tags":[]}],"categories":[],"tags":[]}